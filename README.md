# ğŸ¤– Tool-Enhanced Chat with Groq and FastMCP

This project demonstrates how to integrate a local tool service (`FastMCP`) with Groq's OpenAI-compatible LLM API (e.g., `qwen/qwen3-32b`) for dynamic function calling. The LLM can interpret user intent, automatically call tools, and respond with a natural language answer.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ server.py       # Tool server (weather and stock) using FastMCP
â”œâ”€â”€ client.py       # Chat client that connects to Groq + FastMCP
â”œâ”€â”€ README.md       # This documentation
```

---

## âœ… Features

- Register tools using `FastMCP` (`weather`, `stock`)
- Use Groq LLM (e.g., Qwen model) to interpret user queries
- Let the LLM decide when to call tools using OpenAI's function-calling schema
- Forward tool results back to LLM for final, natural-language answers

---

## ğŸ“¦ Requirements

- Python 3.8+
- Install dependencies:

```
pip install groq fastmcp
```

---

## ğŸš€ Running the Tool Server

The tool server provides two mock tools:

- `weather(city: str)` â€“ Returns static weather info
- `stock(code: str)` â€“ Returns static stock price info

To start the server:

```
python server.py
```

> This launches the FastMCP server at `http://127.0.0.1:4200/demo`

---

## ğŸ’¬ Running the Chat Client

The chat client will:

1. Connect to the MCP server and load tool schemas
2. Send a user query to Groq's LLM
3. Let the model decide if tools should be invoked
4. Use returned tool results to generate the final reply

To start the client:

```
python client.py
```

You can change the user query by modifying the `USER_QUERY` variable at the bottom of `client.py`.

Example:

```python
USER_QUERY = "æŸ¥è¯¢åŒ—äº¬å¤©æ°”å’Œè´µå·èŒ…å°è‚¡ä»·"
```

---

## ğŸ§ª Sample Output

```
Tool calls detected:
Calling tool: weather ...
Tool result: {'temp': 25, 'condition': 'Sunny'}
Calling tool: stock ...
Tool result: {'name': 'è´µå·èŒ…å°', 'price': 1825.0'}

Final response: åŒ—äº¬å½“å‰å¤©æ°”æ™´ï¼Œæ°”æ¸©25åº¦ã€‚è´µå·èŒ…å°å½“å‰è‚¡ä»·ä¸º1825.0å…ƒã€‚
```

---

## ğŸ›  Notes

- Ensure `server.py` is running **before** launching `client.py`
- The tools return mock data; you can replace them with real APIs
- Groq must be accessible and requires a valid `api_key` set in `client.py`
- This project uses synchronous Groq API (as async is not yet supported)

---

## ğŸ“„ License

MIT License. Free to use for personal and commercial projects.
